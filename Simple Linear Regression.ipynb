{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x와 y data, W와 b의 초기값, hypothesis 함수, cost 함수 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [1,2,3,4,5]\n",
    "y_data = [1,2,3,4,5]\n",
    "\n",
    "# 초기값 지정 : 임의값 지정 가능\n",
    "W = tf.Variable(2.9)\n",
    "b = tf.Variable(0.5)\n",
    "\n",
    "# hypothesis 함수\n",
    "hypothesis = W * x_data + b\n",
    "\n",
    "# 에러 제곱의 평균\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_data))  # 가설과 실제 데이터의 차이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": 경사를 내려가면서 cost가 최소가 되는 W와 b를 찾는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0|     1.002| -0.008803|  0.000014\n",
      "   10|     1.002|  -0.00851|  0.000013\n",
      "   20|     1.002| -0.008227|  0.000012\n",
      "   30|     1.002| -0.007953|  0.000012\n",
      "   40|     1.002| -0.007688|  0.000011\n",
      "   50|     1.002| -0.007432|  0.000010\n",
      "   60|     1.002| -0.007184|  0.000009\n",
      "   70|     1.002| -0.006945|  0.000009\n",
      "   80|     1.002| -0.006714|  0.000008\n",
      "   90|     1.002|  -0.00649|  0.000008\n",
      "  100|     1.002| -0.006274|  0.000007\n",
      "  110|     1.002| -0.006065|  0.000007\n",
      "  120|     1.002| -0.005863|  0.000006\n",
      "  130|     1.002| -0.005668|  0.000006\n",
      "  140|     1.002| -0.005479|  0.000006\n",
      "  150|     1.001| -0.005297|  0.000005\n",
      "  160|     1.001| -0.005121|  0.000005\n",
      "  170|     1.001|  -0.00495|  0.000004\n",
      "  180|     1.001| -0.004785|  0.000004\n",
      "  190|     1.001| -0.004626|  0.000004\n",
      "  200|     1.001| -0.004472|  0.000004\n",
      "  210|     1.001| -0.004323|  0.000003\n",
      "  220|     1.001| -0.004179|  0.000003\n",
      "  230|     1.001|  -0.00404|  0.000003\n",
      "  240|     1.001| -0.003906|  0.000003\n",
      "  250|     1.001| -0.003776|  0.000003\n",
      "  260|     1.001|  -0.00365|  0.000002\n",
      "  270|     1.001| -0.003528|  0.000002\n",
      "  280|     1.001| -0.003411|  0.000002\n",
      "  290|     1.001| -0.003297|  0.000002\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "for i in range(300):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = W * x_data + b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "\n",
    "    # W_grad : W의 미분값, b_grad : b의 미분값\n",
    "    W_grad, b_grad = tape.gradient(cost, [W, b])\n",
    "\n",
    "    # x.assing_sub(y) => x -= y\n",
    "    W.assign_sub(learning_rate * W_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(\"{:5}|{:10.4}|{:10.4}|{:10.6f}\".format(i, W.numpy(), b.numpy(), cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습을 반복함에 따라 W는 1에, b는 0에 수렴한다. \n",
    "### Cost 가 계속 줄어듦으로 W와 b의 예측 모델이 점점 정확해진다는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 적용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5.0012317, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(W * 5 + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.4990165, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(W * 2.5 + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델의 예측값이 실제값과 매우 유사함을 알 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
